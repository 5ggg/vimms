{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute fragmentation performance from mzML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we calculate performance for section 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\joewa\\\\Work\\\\git\\\\vimms')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms.Common import *\n",
    "from vimms.Roi import *\n",
    "from vimms.MassSpec import *\n",
    "from vimms.TopNExperiment import *\n",
    "from vimms.PlotsForPaper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:\\\\Users\\\\joewa\\\\University of Glasgow\\\\Vinny Davies - CLDS Metabolomics Project\\\\'\n",
    "manuscript_data_dir = 'C:\\\\Users\\\\joewa\\\\Work\\\\data\\\\evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = os.path.join(base_dir, 'Manuscript\\\\2.4. Varying Multiple Parameters in Top-N Simulations') \n",
    "real_file = os.path.join(result_dir, 'beerqcb_real_results.p')\n",
    "simulated_file = os.path.join(result_dir, 'beerqcb_mzml_simulated_results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [1, 2, 3, 4, 5, 10, 15, 20, 35, 50]\n",
    "rt_tols = [15, 30, 60, 120]\n",
    "experiment_name = 'beerqcb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many ground truth peaks were found by xcms for each fullscan mzML\n",
    "- P = peaks picked by XCMS from the ms1 data (ground truth)\n",
    "- Q = peaks picked by XCMS from the fragmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ms1_intensity = 0\n",
    "# rt_range = [(3*60, 21*60)]\n",
    "rt_range = [(0, 1600)]\n",
    "mz_range = [(0, math.inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(manuscript_data_dir, 'ground_truth\\\\mzML')   \n",
    "csv_file = os.path.join(results_dir, 'extracted_peaks_ms1_alternative_2.csv')\n",
    "P_peaks_df = get_df(csv_file, min_ms1_intensity, rt_range, mz_range)\n",
    "P_count_df = P_peaks_df.groupby('filename').size().reset_index(name='counts')\n",
    "P_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(base_dir, 'Data\\\\Fusion_1578_Ronan_Daly_CLP_pHILIC_22May19\\\\Positive\\\\fragmentation\\\\mzML\\\\extracted_peaks_ms1_alternative_2.csv')\n",
    "Q_peaks_real_df = get_df(csv_file, min_ms1_intensity, rt_range, mz_range)\n",
    "Q_count_real_df = Q_peaks_real_df.groupby('filename').size().reset_index(name='counts')\n",
    "Q_count_real_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(manuscript_data_dir, '%s\\\\mzML\\\\extracted_peaks_ms1_alternative_2.csv' % experiment_name)\n",
    "Q_peaks_simulated_df = get_df(csv_file, min_ms1_intensity, rt_range, mz_range)\n",
    "Q_count_simulated_df = Q_peaks_simulated_df.groupby('filename').size().reset_index(name='counts')\n",
    "Q_count_simulated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(N, rt_tol, controller_file, chemicals_file, fragfile, P_peaks_df, Q_peaks_df, scenario):\n",
    "    return {\n",
    "        'fragfile': fragfile,\n",
    "        'N': N,\n",
    "        'rt_tol': rt_tol,\n",
    "        'roi_mz_tol': 30,\n",
    "        'roi_min_length': 1,\n",
    "        'roi_min_ms1_intensity': 0,        \n",
    "        'fragmentation_min_ms1_intensity': 0,\n",
    "        'min_rt': rt_range[0][0],\n",
    "        'max_rt': rt_range[0][1],\n",
    "        'fullscan_filename': 'QCB_22May19_1.mzML',\n",
    "        'P_peaks_df': P_peaks_df,\n",
    "        'Q_peaks_df': Q_peaks_df,\n",
    "        'matching_mz_tol': 10,\n",
    "        'matching_rt_tol': 30,\n",
    "        'scenario': scenario,\n",
    "        'controller_file': controller_file,\n",
    "        'chemicals_file': chemicals_file\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Real Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragfile_dir = os.path.join(base_dir, 'Data\\\\Fusion_1578_Ronan_Daly_CLP_pHILIC_22May19\\\\Positive\\\\fragmentation\\\\mzML\\\\*.mzML')\n",
    "fragfiles = glob.glob(fragfile_dir)\n",
    "\n",
    "filtered_fragfiles = []\n",
    "for fragfile in fragfiles:\n",
    "    N, rt_tol = get_N_rt_tol_from_qcb_filename(fragfile)     \n",
    "    if 'QCB_N' not in fragfile:\n",
    "        continue\n",
    "    filtered_fragfiles.append(fragfile)\n",
    "        \n",
    "len(filtered_fragfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = []\n",
    "for fragfile in filtered_fragfiles:\n",
    "    N, rt_tol = get_N_rt_tol_from_qcb_filename(fragfile)     \n",
    "     # extract chemicals from fullscan file\n",
    "    chemicals_file = os.path.join(manuscript_data_dir, experiment_name, 'mzML\\\\dataset.p')\n",
    "     # extract frag events from fragfile    \n",
    "    controller_file = fragfile\n",
    "    # all_params.append(get_params(N, rt_tol, controller_file, chemicals_file, fragfile, P_peaks_df, Q_peaks_real_df, 1))\n",
    "    all_params.append(get_params(N, rt_tol, controller_file, chemicals_file, fragfile, P_peaks_df, Q_peaks_real_df, 2))\n",
    "len(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_df = evaluate_serial(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = evaluate_parallel(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(real_df, real_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Simulated Performance from mzML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragfile_dir = os.path.join(manuscript_data_dir, experiment_name, 'mzML\\\\')\n",
    "all_params = []\n",
    "for N in Ns:\n",
    "    for rt_tol in rt_tols:\n",
    "        fragfile = os.path.join(fragfile_dir, 'experiment_%s_N_%d_rttol_%d.mzML' % (experiment_name, N, rt_tol))        \n",
    "        \n",
    "        # extract chemicals and fragmentation events from mzML file\n",
    "        # chemicals_file = fragfile\n",
    "        # controller_file = fragfile\n",
    "        \n",
    "        # load chemicals and fragmentation events from controller\n",
    "        # chemicals_file = os.path.join(fragfile_dir, 'dataset.p')      \n",
    "        # controller_file = os.path.join(fragfile_dir, 'experiment_%s_N_%d_rttol_%d.p' % (experiment_name, N, rt_tol))                \n",
    "          \n",
    "        # extract chemicals from fullscan file\n",
    "        chemicals_file = os.path.join(fragfile_dir, 'dataset.p')              \n",
    "        # extract frag events from mzML file\n",
    "        controller_file = fragfile\n",
    "            \n",
    "        # all_params.append(get_params(N, rt_tol, controller_file, chemicals_file, fragfile, P_peaks_df, Q_peaks_simulated_df, 1))\n",
    "        all_params.append(get_params(N, rt_tol, controller_file, chemicals_file, fragfile, P_peaks_df, Q_peaks_simulated_df, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df = evaluate_parallel(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(simulated_df, simulated_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = load_obj(real_file)\n",
    "simulated_df = load_obj(simulated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 2\n",
    "real_df = real_df[real_df['scenario'] == scenario]\n",
    "simulated_df = simulated_df[simulated_df['scenario'] == scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df['data'] = 'real'\n",
    "simulated_df['data'] = 'simulated'\n",
    "combined_df = pd.concat([real_df, simulated_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1 = np.concatenate([real_df['F1'].values, simulated_df['F1'].values])\n",
    "ylim = [min(all_f1)-0.05, max(all_f1)+0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot(df, column_name, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.lineplot(x='N', y=column_name, hue='rt_tol', legend='brief', data=df, palette=sns.color_palette(\"Blues\")[0:4])\n",
    "    legend = ax.legend()\n",
    "    legend.texts[0].set_text('DEW (s)')\n",
    "    plt.title(title)\n",
    "    for l in ax.lines:\n",
    "        plt.setp(l, linewidth=5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'TP'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'FP'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'FN'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Prec'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Rec'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'F1'\n",
    "lineplot(real_df, column_name, 'BeerQCB (Real)')\n",
    "lineplot(simulated_df, column_name, 'BeerQCB (Simulated)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(result_df, column_name, N, rt_tol, scenario):\n",
    "    idx = (result_df['N'] == N) & (result_df['rt_tol'] == rt_tol) & (result_df['scenario'] == scenario)\n",
    "    row = result_df[idx]\n",
    "    val = row[column_name].values[0]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap(mat, xticklabels, yticklabels, title, xlabel, ylabel, vmin, vmax, outfile):\n",
    "    plt.figure(figsize=(6, 6))    \n",
    "    ax = sns.heatmap(mat, xticklabels=xticklabels, yticklabels=yticklabels, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # for l in ax.lines:\n",
    "    #     plt.setp(l, linewidth=5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_real = np.zeros((len(Ns), len(rt_tols)))\n",
    "f1_simulated = np.zeros((len(Ns), len(rt_tols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 2\n",
    "for i in range(len(Ns)):\n",
    "    N = Ns[i]\n",
    "    for j in range(len(rt_tols)):\n",
    "        rt_tol = rt_tols[j]\n",
    "        f1_real[i, j] = get_value(real_df, 'F1', N, rt_tol, scenario)\n",
    "        f1_simulated[i, j] = get_value(simulated_df, 'F1', N, rt_tol, scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_f1 = np.concatenate([real_df['F1'].values, simulated_df['F1'].values])\n",
    "ylim = [min(all_f1), max(all_f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_data = np.array([f1_real.flatten(), f1_simulated.flatten()]).transpose()\n",
    "boxplot_data\n",
    "boxplot_df = pd.DataFrame(boxplot_data, columns=['Real', 'Simulated'])\n",
    "boxplot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=boxplot_df)\n",
    "ax.set_ylabel('F1-score')\n",
    "ax.set_xticklabels(['Real', 'Simulated'])\n",
    "# plt.title('Fragmentation Performance (BeerQCB)', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('qcb_fragmentation_performance.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap(f1_real, rt_tols, Ns, None, 'DEW (s)', 'Top-N', ylim[0], ylim[1],\n",
    "             'qcb_real_performance_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap(f1_simulated, rt_tols, Ns, None, 'DEW (s)', 'Top-N', ylim[0], ylim[1],\n",
    "             'qcb_simulated_performance_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df.nlargest(5, 'F1').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df.nlargest(5, 'F1').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df.nsmallest(5, 'F1').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_df.nsmallest(5, 'F1').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_diff = f1_simulated - f1_real\n",
    "make_heatmap(f1_diff, rt_tols, Ns, None, 'DEW (s)', 'Top-N', None, None,\n",
    "             'qcb_diff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
